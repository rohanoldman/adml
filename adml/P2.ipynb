{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81eeee8f",
   "metadata": {},
   "source": [
    "Practical 2 : Program to implement regularization to prevent the model from overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1455138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 4s 6ms/step - loss: 1.1208 - accuracy: 0.8822 - val_loss: 0.6079 - val_accuracy: 0.9151\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.5569 - accuracy: 0.9220 - val_loss: 0.4951 - val_accuracy: 0.9341\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4875 - accuracy: 0.9309 - val_loss: 0.4566 - val_accuracy: 0.9390\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4521 - accuracy: 0.9358 - val_loss: 0.4253 - val_accuracy: 0.9423\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4245 - accuracy: 0.9400 - val_loss: 0.4090 - val_accuracy: 0.9437\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.4027 - accuracy: 0.9439 - val_loss: 0.3803 - val_accuracy: 0.9486\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3837 - accuracy: 0.9474 - val_loss: 0.3610 - val_accuracy: 0.9520\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3685 - accuracy: 0.9489 - val_loss: 0.3452 - val_accuracy: 0.9552\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3519 - accuracy: 0.9516 - val_loss: 0.3399 - val_accuracy: 0.9561\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3410 - accuracy: 0.9530 - val_loss: 0.3418 - val_accuracy: 0.9493\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "# Load the data\n",
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.mnist.load_data() \n",
    "\n",
    "# Preprocess the data\n",
    "train_data = train_data.reshape((60000, 784)) / 255.0 \n",
    "test_data = test_data.reshape((10000, 784)) / 255.0 \n",
    "train_labels = tf.keras.utils.to_categorical(train_labels) \n",
    "test_labels = tf.keras.utils.to_categorical(test_labels) \n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,), kernel_regularizer=tf.keras.regularizers.l2(0.01)), \n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)), \n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, train_labels, \n",
    "                    epochs=10, \n",
    "                    batch_size=128,\n",
    "                    validation_data=(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25619497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 4s 6ms/step - loss: 1.1238 - accuracy: 0.8819 - val_loss: 0.5999 - val_accuracy: 0.9229\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.5588 - accuracy: 0.9200 - val_loss: 0.5078 - val_accuracy: 0.9301\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4897 - accuracy: 0.9299 - val_loss: 0.4453 - val_accuracy: 0.9421\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4492 - accuracy: 0.9363 - val_loss: 0.4280 - val_accuracy: 0.9412\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4226 - accuracy: 0.9405 - val_loss: 0.4161 - val_accuracy: 0.9357\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4012 - accuracy: 0.9436 - val_loss: 0.3893 - val_accuracy: 0.9427\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3834 - accuracy: 0.9470 - val_loss: 0.3841 - val_accuracy: 0.9431\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3677 - accuracy: 0.9481 - val_loss: 0.3456 - val_accuracy: 0.9558\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3542 - accuracy: 0.9506 - val_loss: 0.3374 - val_accuracy: 0.9537\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3398 - accuracy: 0.9527 - val_loss: 0.3294 - val_accuracy: 0.9530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This code trains the model using the fit() function. The training data and labels are passed in as arguments,\\nalong with the number of epochs to train for, the batch size to use, and the validation data to use for\\nmonitoring model performance during training. The fit() function returns a history object that contains information\\nabout the training process, such as the loss and accuracy at each epoch.\\nThe purpose of this program is to demonstrate how to implement a neural network model for image classification\\nusing TensorFlow/Keras. The model uses regularization techniques to prevent overfitting and achieves high accuracy\\non the MNIST dataset.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the data\n",
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "'''Loads the MNIST dataset using the load_data() function provided by Keras, a high-level API of TensorFlow.\n",
    "The MNIST dataset contains 70,000 images of handwritten digits that are split into 60,000 training images and 10,000 testing images.'''\n",
    "\n",
    "# Preprocess the data\n",
    "train_data = train_data.reshape((60000, 784)) / 255.0   # Reshape and normalize training data\n",
    "test_data = test_data.reshape((10000, 784)) / 255.0     # Reshape and normalize testing data\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)   # Convert training labels to one-hot encoding\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)     # Convert testing labels to one-hot encoding\n",
    "\n",
    "'''Preprocess the data. The images are first reshaped from a 3D array (28x28 pixels) to a 2D array (784 pixels).\n",
    "Then, the pixel values are normalized to be between 0 and 1 by dividing by 255.\n",
    "The labels are converted to one-hot encoding format using the to_categorical() function provided by Keras.\n",
    "This is done to make it easier for the model to classify the images into 10 different classes (one for each digit).'''\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Define sequential model\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,), kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    # Add a fully connected layer with 128 units, ReLU activation, and L2 regularization\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    # Add another fully connected layer with 64 units, ReLU activation, and L2 regularization\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "    # Add a final output layer with 10 units (one for each class), softmax activation\n",
    "])\n",
    "\n",
    "'''This code defines the architecture of the neural network model.\n",
    "The Sequential() function is used to create a sequential model, meaning that the layers are added in sequence.\n",
    "Three fully connected layers are defined using the Dense() function.\n",
    "The first layer has 128 units, ReLU activation, and L2 regularization with a regularization parameter of 0.01.\n",
    "The second layer has 64 units, ReLU activation, and L2 regularization with a regularization parameter of 0.01.\n",
    "The third and final layer has 10 units, softmax activation, and is used for the classification task.'''\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),   # Use Adam optimizer with learning rate 0.001\n",
    "    loss='categorical_crossentropy',    # Use categorical cross-entropy loss function\n",
    "    metrics=['accuracy']    # Monitor accuracy during training\n",
    ")\n",
    "\n",
    "'''This code compiles the model. The compile() function configures the model for training by specifying the optimizer,\n",
    "loss function, and metrics to monitor during training.\n",
    "In this case, the Adam optimizer is used with a learning rate of 0.001, categorical cross-entropy is used as the loss function,\n",
    "and accuracy is monitored during training.'''\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_data=(test_data, test_labels)\n",
    ")\n",
    "'''This code trains the model using the fit() function. The training data and labels are passed in as arguments,\n",
    "along with the number of epochs to train for, the batch size to use, and the validation data to use for\n",
    "monitoring model performance during training. The fit() function returns a history object that contains information\n",
    "about the training process, such as the loss and accuracy at each epoch.\n",
    "The purpose of this program is to demonstrate how to implement a neural network model for image classification\n",
    "using TensorFlow/Keras. The model uses regularization techniques to prevent overfitting and achieves high accuracy\n",
    "on the MNIST dataset.'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4720a88c",
   "metadata": {},
   "source": [
    "'''This code trains the model using the fit() function. The training data and\n",
    "labels are passed in as arguments, \\nalong with the number of epochs to train\n",
    "for, the batch size to use, and the validation data to use for \\nmonitoring\n",
    "model performance during training. The fit() function returns a history object\n",
    "that contains information \\nabout the training process, such as the loss and\n",
    "accuracy at each epoch.\\n\\nThe purpose of this program is to demonstrate how to\n",
    "implement a neural network model for image classification \\nusing\n",
    "TensorFlow/Keras. The model uses regularization techniques to prevent\n",
    "overfitting and achieves high accuracy \\non the MNIST dataset.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852ffd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
